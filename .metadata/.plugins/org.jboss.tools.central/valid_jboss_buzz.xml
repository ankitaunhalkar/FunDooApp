<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Troubleshooting Open vSwitch DPDK PMD Thread Core Affinity</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/sAl7QRmVmUk/" /><category term="Red Hat Enterprise Linux" /><category term="affinity" /><category term="datapath" /><category term="dpdk" /><category term="Open vSwitch" /><category term="openvswitch" /><category term="ovs-dpdk" /><category term="poll mode driver" /><category term="troubleshooting" /><author><name>Eelco Chaudron</name></author><id>https://developers.redhat.com/blog/?p=502737</id><updated>2018-06-20T11:00:34Z</updated><published>2018-06-20T11:00:34Z</published><content type="html">&lt;p&gt;The most common problem when people are trying to deploy an &lt;a href="http://docs.openvswitch.org/en/latest/intro/install/dpdk/"&gt;Open vSwitch with Data Plane Development Kit&lt;/a&gt; (OvS-DPDK) solution is that the performance is not as expected. For example, they are losing packets. This is where our journey for this series of blogs will start.&lt;/p&gt; &lt;p&gt;This first blog is about Poll Mode Driver (PMD) thread core affinity. It covers how to configure thread affinity and how to verify that it’s set up correctly. This includes making sure no other threads are using the CPU cores.&lt;/p&gt; &lt;p&gt;&lt;span id="more-502737"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2 id="dedicate-cpu-cores-to-the-pmd-threads"&gt;Dedicate CPU Cores to the PMD Threads&lt;/h2&gt; &lt;p&gt;PMD threads are the threads that handle the receiving and processing of packets from the assigned receive queues. They do this in a tight loop, and anything interrupting these threads can cause packets to be dropped. That is why these threads &lt;strong&gt;must&lt;/strong&gt; run on a dedicated CPU core; that is, no other threads in the system should run on this core. This is also true for various Linux kernel tasks.&lt;/p&gt; &lt;p&gt;Let’s assume you would like to use CPU cores 1 and 15 (a single hyper-thread pair) for your PMD threads. This will convert into a &lt;code&gt;pmd-cpu-mask&lt;/code&gt; mask of &lt;code&gt;0x8002&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To manually accomplish the isolation you have to do the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use the Linux kernel command line option &lt;code&gt;isolcpus&lt;/code&gt; to isolate the PMD cores from the general SMP balancing and scheduling algorithms. For the example above, you would use the following: &lt;code&gt;isolcpus=1,15&lt;/code&gt;. Please note that the &lt;code&gt;isolcpus=&lt;/code&gt; parameter is deprecated in favor of cpusets. For more information check the &lt;a href="https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt"&gt;kernel documentation&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Reducing the number of clock tick interrupts can be done with the combined &lt;code&gt;nohz=on nohz_full=1,15&lt;/code&gt; command-line options. This reduces the times the PMD threads get interrupted for servicing timer interrupts. More details on this subject can be found here: &lt;a href="https://www.kernel.org/doc/Documentation/timers/NO_HZ.txt"&gt;NO_HZ.txt&lt;/a&gt;&lt;/li&gt; &lt;li&gt;For the above to work correctly we need another command-line option, &lt;code&gt;rcu_nocbs=1,15&lt;/code&gt;, or else the kernel will still interrupt the thread; details are in the same document: &lt;a href="https://www.kernel.org/doc/Documentation/timers/NO_HZ.txt"&gt;NO_HZ.txt&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: For the above kernel options you might need to add additional cores that also need isolation. For example, cores assigned to one or more virtual machines and the cores configured by the &lt;code&gt;dpdk-lcore-mask&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To make all of the above more convenient you could use a tuned profile called &lt;code&gt;cpu-partitioning&lt;/code&gt; for this. There is a somewhat older blog on &lt;a href="https://servicesblog.redhat.com/2012/04/16/tuning-your-system-with-tuned/"&gt;tuned&lt;/a&gt; that might be helpful. However, in short, this is how you configure it:&lt;/p&gt; &lt;pre&gt;# systemctl enable tuned # systemctl start tuned # echo isolated_cores=1,15 &amp;#62;&amp;#62; /etc/tuned/cpu-partitioning-variables.conf # echo no_balance_cores=1,15 &amp;#62;&amp;#62; /etc/tuned/cpu-partitioning-variables.conf # tuned-adm profile cpu-partitioning # reboot&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you’re tuned version is lower than tuned-2.9.0-1 you still need to set up &lt;code&gt;isolcpus&lt;/code&gt; manually as indicated above and omit the &lt;code&gt;no_balance_cores=&lt;/code&gt;.&lt;/p&gt; &lt;h2 id="verify-cpu-assignments"&gt;Verify CPU Assignments&lt;/h2&gt; &lt;h3 id="command-line-options"&gt;Command-line Options&lt;/h3&gt; &lt;p&gt;First, check the Linux command-line options to see if they are configured as expected:&lt;/p&gt; &lt;pre&gt;# cat /proc/cmdline BOOT_IMAGE=/vmlinuz-3.10.0-693.17.1.el7.x86_64 \ root=/dev/mapper/rhel_wsfd--netdev64-root ro crashkernel=auto \ rd.lvm.lv=rhel_wsfd-netdev64/root rd.lvm.lv=rhel_wsfd-netdev64/swap \ console=ttyS1,115200 iommu=pt intel_iommu=on \ default_hugepagesz=1G hugepagesz=1G hugepages=32 \ &lt;b&gt;isolcpus=1&lt;/b&gt;,2,3,4,5,6,&lt;b&gt;15&lt;/b&gt;,16,17,18,19,20 skew_tick=1 \ &lt;b&gt;nohz=on nohz_full=1&lt;/b&gt;,2,3,4,5,6,&lt;b&gt;15&lt;/b&gt;,16,17,18,19,20 \ &lt;b&gt;rcu_nocbs=1&lt;/b&gt;,2,3,4,5,6,&lt;b&gt;15&lt;/b&gt;,16,17,18,19,20 tuned.non_isolcpus=0fe07f81 intel_pstate=disable nosoftlockup &lt;/pre&gt; &lt;h3 id="pmd-thread-affinity"&gt;PMD Thread Affinity&lt;/h3&gt; &lt;p&gt;Second, make sure the PMD threads are/will be running on the correct threads. In this example you see they are assigned to the wrong CPUs, 11 and 27:&lt;/p&gt; &lt;pre&gt;# pidstat -t -p `pidof ovs-vswitchd` 1 | grep -E pmd\|%CPU 06:41:21 UID TGID TID %usr %system %guest %CPU CPU Command 06:41:22 995 - 1316 100.00 0.00 0.00 100.00 27 |__pmd33 06:41:22 995 - 1317 100.00 0.00 0.00 100.00 11 |__pmd32 06:41:22 UID TGID TID %usr %system %guest %CPU CPU Command 06:41:23 995 - 1316 100.00 0.00 0.00 100.00 27 |__pmd33 06:41:23 995 - 1317 100.00 0.00 0.00 100.00 11 |__pmd32&lt;/pre&gt; &lt;p&gt;In this case, it’s due to a known bug in &lt;code&gt;tuned&lt;/code&gt; that moves away processes running on the isolated cores prior to its initialization. Running &lt;code&gt;sytemctl restart openvswitch&lt;/code&gt; will solve this specific issue:&lt;/p&gt; &lt;pre&gt;# systemctl restart openvswitch # pidstat -t -p `pidof ovs-vswitchd` 1 | grep -E pmd\|%CPU 06:44:01 UID TGID TID %usr %system %guest %CPU CPU Command 06:44:02 995 - 2774 100.00 0.00 0.00 100.00 1 |__pmd32 06:44:02 995 - 2775 100.00 0.00 0.00 100.00 15 |__pmd33 06:44:02 UID TGID TID %usr %system %guest %CPU CPU Command 06:44:03 995 - 2774 100.00 0.00 0.00 100.00 1 |__pmd32 06:44:03 995 - 2775 100.00 0.00 0.00 100.00 15 |__pmd33&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Until the &lt;code&gt;tuned&lt;/code&gt; issue is fixed, you always have to restart OVS after a &lt;code&gt;tuned&lt;/code&gt; restart to get the correct CPU assignments!&lt;/p&gt; &lt;p&gt;To be 100% sure the Linux kernel is not scheduling your PMD thread on another core use the &lt;code&gt;taskset&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt;# taskset -pc 2774 pid 2774's current affinity list: 1 # taskset -pc 2775 pid 2775's current affinity list: 15&lt;/pre&gt; &lt;h3 id="other-threads-using-the-pmd-cores"&gt;Other Threads Using the PMD Cores&lt;/h3&gt; &lt;p&gt;Finally, make sure that no other threads are scheduled on the PMD cores. The following command will give the CPU affinity for all running userspace threads:&lt;/p&gt; &lt;pre&gt;find -L /proc/[0-9]*/exe ! -type l | cut -d / -f3 | \ xargs -l -i sh -c 'ps -p {} -o comm=; taskset -acp {}'&lt;/pre&gt; &lt;p&gt;Below is a partial example output. Here you can see that my &lt;code&gt;bash&lt;/code&gt; process is using the PMD reserved CPU cores:&lt;/p&gt; &lt;pre&gt;... agetty pid 1443's current affinity list: 0,7-14,21-27 bash pid 14863's current affinity list: 0-15 systemd pid 1's current affinity list: 0,7-14,21-27 ovs-vswitchd pid 3777's current affinity list: 2 pid 3778's current affinity list: 0,7-14,21-27 pid 3780's current affinity list: 2 pid 3781's current affinity list: 16 pid 3782's current affinity list: 2 pid 3785's current affinity list: 2 pid 3786's current affinity list: 2 pid 3815's current affinity list: 1 pid 3816's current affinity list: 15 pid 3817's current affinity list: 2 pid 3818's current affinity list: 2 pid 3819's current affinity list: 2 pid 3820's current affinity list: 2 ...&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: You could also use a tool called &lt;a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_MRG/1.3/html/Tuna_User_Guide/index.html"&gt;Tuna&lt;/a&gt;, to list all processes running on a specific core.&lt;/p&gt; &lt;p&gt;If you verify all the above, you will prevent other threads and the kernel from interfering with the PMD threads. Don’t forget to re-check the above if you make any major changes to your environment.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;linkname=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;linkname=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;linkname=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;linkname=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;linkname=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;linkname=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;linkname=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;linkname=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F20%2Ftroubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity%2F&amp;#38;title=Troubleshooting%20Open%20vSwitch%20DPDK%20PMD%20Thread%20Core%20Affinity" data-a2a-url="https://developers.redhat.com/blog/2018/06/20/troubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity/" data-a2a-title="Troubleshooting Open vSwitch DPDK PMD Thread Core Affinity"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/20/troubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity/"&gt;Troubleshooting Open vSwitch DPDK PMD Thread Core Affinity&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/sAl7QRmVmUk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The most common problem when people are trying to deploy an Open vSwitch with Data Plane Development Kit (OvS-DPDK) solution is that the performance is not as expected. For example, they are losing packets. This is where our journey for this series of blogs will start. This first blog is about Poll Mode Driver (PMD) [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/20/troubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity/"&gt;Troubleshooting Open vSwitch DPDK PMD Thread Core Affinity&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/06/20/troubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">502737</post-id><dc:creator>Eelco Chaudron</dc:creator><dc:date>2018-06-20T11:00:34Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/06/20/troubleshooting-open-vswitch-dpdk-pmd-thread-core-affinity/</feedburner:origLink></entry><entry><title>Red Hat Data Grid on Three Clouds (the details behind the demo)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/CVkkT6u3OR0/" /><category term="Red Hat JBoss Data Grid" /><category term="Red Hat OpenShift Container Platform" /><category term="Red Hat Summit" /><category term="Apache OpenWhisk" /><category term="cloud" /><category term="Cloud Services" /><category term="Data Grid" /><category term="demo" /><category term="Eclipse Vert.x" /><category term="gluster" /><category term="JBoss Data Grid" /><category term="OpenShift Container Platform" /><category term="Red Hat OpenShift" /><category term="red hat summit" /><category term="Red Hat Summit 2018" /><category term="vert.x" /><author><name>Sebastian Łaskawiec</name></author><id>https://developers.redhat.com/blog/?p=499757</id><updated>2018-06-19T11:00:57Z</updated><published>2018-06-19T11:00:57Z</published><content type="html">&lt;p&gt;If you saw or heard about the &lt;a href="https://developers.redhat.com/blog/2018/05/10/red-hat-summit-2018-burr-sutter-demo/"&gt;multi-cloud demo at Red Hat Summit 2018&lt;/a&gt;, this article details how we ran &lt;a href="https://developers.redhat.com/products/datagrid/overview/"&gt;Red Hat Data Grid&lt;/a&gt; in active-active-active mode across three cloud providers. This set up enabled us to show a fail over between cloud providers in real time with no loss of data. In addition to Red Hat Data Grid, we used &lt;a href="https://developers.redhat.com/blog/2018/03/13/eclipse-vertx-first-application/"&gt;Vert.x&lt;/a&gt; (reactive programming), &lt;a href="https://developers.redhat.com/blog/category/topics/serverless/"&gt;OpenWhisk&lt;/a&gt; (serverless), and &lt;a href="https://www.redhat.com/en/technologies/storage/gluster"&gt;Red Hat Gluster Storage&lt;/a&gt; (software-defined storage.)&lt;/p&gt; &lt;p&gt;This year’s &lt;a href="https://developers.redhat.com/blog/tag/red-hat-summit-2018/"&gt;Red Hat Summit&lt;/a&gt; was quite an adventure for all of us. A trip to San Francisco is probably on the bucket list of IT geeks from all over the world. Also, we were able to meet many other Red Hatters, who work remotely for Red Hat as we do.  However, the best part was that we had something important to say: “we believe in the hybrid/multi cloud&amp;#8221; and we got to prove that live on stage.&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-499827 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image5-2-1024x685.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image5-2-1024x685.png" alt="" width="640" height="428" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image5-2-1024x685.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image5-2-300x201.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image5-2-768x514.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image5-2.png 1299w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;address style="text-align: center;"&gt;&lt;em&gt;Photo credit: Bolesław Dawidowicz&lt;/em&gt;&lt;/address&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span id="more-499757"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h3&gt;Our keynote demo&lt;/h3&gt; &lt;p&gt;In one of the earlier keynote demos, our hybrid cloud was provisioned live in a rack on stage with Red Hat OpenShift. It was quite impressive to see all the tools working together to make the demo succeed. Together with a group of teammates, we were responsible for creating the fourth keynote demo, which involved interesting middleware technologies such as Red Hat Data Grid, Vert.x, OpenWhisk, and Red Hat Gluster.  You watch the demo online if you haven&amp;#8217;t already seen it:&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='390' src='https://www.youtube.com/embed/hu2BmE1Wk_Q?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;What you couldn’t see is that we had a maintenance team sitting behind the scenes, observing whether everything was fine (below, Marek Posolda from the Red Hat SSO team and Galder Zamarreño from the Red Hat Data Grid team):&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-499797 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image6-1024x769.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image6-1024x769.png" alt="" width="640" height="481" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image6-1024x769.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image6-300x225.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image6-768x577.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image6.png 1241w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;The demo went well, so it&amp;#8217;s time to explain how we did it.&lt;/p&gt; &lt;h3&gt;Keynote Demo #4 Architecture&lt;/h3&gt; &lt;p&gt;We were using three data centers (Amazon, Azure, and the on-stage rack) that were working in an active-active-active replication configuration.&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-499777 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image2-1024x575.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image2-1024x575.png" alt="" width="640" height="359" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image2-1024x575.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image2-300x168.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image2-768x431.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image2.png 1252w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;Each site was using a microservices and serverless architecture. We also used two storage layers: Gluster for storing images and Red Hat Data Grid for storing metadata (in JSON format):&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-499767 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image1-1024x472.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image1-1024x472.png" alt="" width="640" height="295" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image1-1024x472.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image1-300x138.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image1-768x354.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image1.png 1264w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;h3&gt;Data Grid Setup for Cross-site Replication&lt;/h3&gt; &lt;p&gt;The active-active-active setup for Red Hat Data Grid was implemented using &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_data_grid/7.2/html/administration_and_configuration_guide/set_up_cross_datacenter_replication"&gt;Cross-site replication&lt;/a&gt; (also known as x-site replication) feature. However, we had to slightly adjust the configuration:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-499787 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image3.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image3.png" alt="" width="996" height="341" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/image3.png 996w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image3-300x103.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/image3-768x263.png 768w" sizes="(max-width: 996px) 100vw, 996px" /&gt;&lt;/p&gt; &lt;p&gt;The sites communicated with each other using Red Hat OpenShift’s load balancer services. The load balancers were allocated up front and their coordinates (all three clouds) were injected into a secret, creating a so-called global cluster discovery string. The configuration XML file was put into a &lt;code&gt;ConfigMap&lt;/code&gt; allowing us to easily update the configuration manually from the UI (if needed).&lt;/p&gt; &lt;p&gt;Since we strongly believe in automation, we created automated setup scripts for provisioning Red Hat Data Grid to all three clouds. The scripts can be found on our &lt;a href="https://github.com/rhdemo/jdg-as-a-service"&gt;GitHub repository&lt;/a&gt;. We also provided a customized version of the scripts that can simulate x-site replication using three different projects. You might start the Red Hat OpenShift Container Platform local instance using the &lt;code&gt;oc cluster up&lt;/code&gt; command and then run &lt;a href="https://github.com/rhdemo/jdg-as-a-service/blob/master/local-full-deployment.sh"&gt;this provisioning script&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Now, let’s have a look at all the configuration bits and explore how they work together (you may check them using the local provisioning script). Let’s start with the global cluster discovery secret:&lt;/p&gt; &lt;p&gt;View the code on &lt;a href="https://gist.github.com/slaskawi/91ff7aff0584f5ebb52b3a2314db46ef"&gt;Gist&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;DISCOVERY&lt;/code&gt; string is specific to &lt;a href="http://www.jgroups.org/manual4/index.html#TCPPING_Prot"&gt;TCPPING&lt;/a&gt;, which was used for global cluster discovery. The next parameter is &lt;code&gt;EXT_ADDR&lt;/code&gt;, which represents the load balancer&amp;#8217;s public IP address. The JGroups communication toolkit needs to bind the global cluster transport to that particular address. &lt;code&gt;SITE&lt;/code&gt; describes the local site: is it Amazon or Azure or is it the private (on-stage rack) one?&lt;/p&gt; &lt;p&gt;The next piece of the puzzle is configuration. The full XML file can be found &lt;a href="https://gist.github.com/slaskawi/ca522cec11c4019b101afb9cbef5e2dd"&gt;here&lt;/a&gt;. In this blog post, we will focus only on the crucial bits:&lt;/p&gt; &lt;p&gt;View the code on &lt;a href="https://gist.github.com/slaskawi/54a7b231d69cf0f953e38baa14f3f368"&gt;Gist&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The local cluster (inside a single data center) discovers all other members using the &lt;a href="https://github.com/jgroups-extras/jgroups-kubernetes"&gt;KUBE_PING&lt;/a&gt; protocol. All the messages are forwarded to other sites using the &lt;a href="http://www.jgroups.org/manual4/index.html#RELAY2"&gt;RELAY2&lt;/a&gt; protocol. The value of &lt;code&gt;jboss.relay.site&lt;/code&gt; is injected into environmental variables using the &lt;a href="https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/"&gt;Downward API&lt;/a&gt; from the &lt;code&gt;jdg-app&lt;/code&gt; secret. The last interesting bit is that &lt;code&gt;max_site_masters&lt;/code&gt; is set to &lt;code&gt;1000&lt;/code&gt;. Since we do not know how many instances there are behind the load balancers, we need to ensure that each one of them can act as a site master and forward all the traffic to the other site.&lt;/p&gt; &lt;p&gt;The next stack is defined for the &lt;code&gt;RELAY&lt;/code&gt; protocol:&lt;/p&gt; &lt;p&gt;View the code on &lt;a href="https://gist.github.com/slaskawi/7483ef2915bf53e2cf2abad080c5f5ab"&gt;Gist&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Starting from the TCP protocol, we need to ensure that we bind into the load balancer public address. That’s why all of the load balancers have to be provisioned up front. Again, we inject this variable from the &lt;code&gt;jdg-app&lt;/code&gt; secret. Another interesting piece is &lt;code&gt;TCPPING&lt;/code&gt;, where we use the global cluster discovery string (from the &lt;code&gt;jdg-app&lt;/code&gt; secret). The &lt;code&gt;FD_ALL&lt;/code&gt; timeout is set to a quite high number, since we would like to tolerate short site downtimes.&lt;/p&gt; &lt;p&gt;View the code on &lt;a href="https://gist.github.com/slaskawi/35c57399c89168e60dbcd2a96bc8baf9"&gt;Gist&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Each site configured all three sites as async backups. This allows achieving an active-active-active kind of setup.&lt;/p&gt; &lt;h3&gt;Final Thoughts&lt;/h3&gt; &lt;p&gt;An active-active-active setup is a very interesting approach for handling a large amount of globally routed traffic. However, a few things need to be considered before implementing it:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Do not write the same key from different data centers. If you do, you may get into trouble very quickly due to network delays.&lt;/li&gt; &lt;li&gt;When the site goes down and comes back up again, you must trigger a state transfer to synchronize it. This is a manual task, but we are working hard to making it fully transparent.&lt;/li&gt; &lt;li&gt;Make sure your application can tolerate asynchronous replication. Cross-site replication with synchronous caches might be problematic.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We learned a lot about globally load-balanced setups during the demo work. Discovering new use cases was quite fun and we believe we know how to make Red Hat Data Grid even better for these kinds of scenarios.&lt;/p&gt; &lt;p&gt;Have fun with the cross-site replication and see you at the next Summit!&lt;br /&gt; The Red Hat Data Grid Team&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;linkname=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;linkname=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;linkname=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;linkname=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;linkname=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;linkname=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;linkname=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;linkname=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F19%2Fred-hat-data-grid-on-three-clouds%2F&amp;#38;title=Red%20Hat%20Data%20Grid%20on%20Three%20Clouds%20%28the%20details%20behind%20the%20demo%29" data-a2a-url="https://developers.redhat.com/blog/2018/06/19/red-hat-data-grid-on-three-clouds/" data-a2a-title="Red Hat Data Grid on Three Clouds (the details behind the demo)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/19/red-hat-data-grid-on-three-clouds/"&gt;Red Hat Data Grid on Three Clouds (the details behind the demo)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/CVkkT6u3OR0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;If you saw or heard about the multi-cloud demo at Red Hat Summit 2018, this article details how we ran Red Hat Data Grid in active-active-active mode across three cloud providers. This set up enabled us to show a fail over between cloud providers in real time with no loss of data. In addition to [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/19/red-hat-data-grid-on-three-clouds/"&gt;Red Hat Data Grid on Three Clouds (the details behind the demo)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/06/19/red-hat-data-grid-on-three-clouds/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">499757</post-id><dc:creator>Sebastian Łaskawiec</dc:creator><dc:date>2018-06-19T11:00:57Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/06/19/red-hat-data-grid-on-three-clouds/</feedburner:origLink></entry><entry><title>JBoss Tools 4.6.0.AM3 for Eclipse Photon.0.RC3</title><link rel="alternate" type="text/html" href="http://feedproxy.google.com/~r/jbossbuzz/~3/jtOEkqNA9Q8/4.6.0.am3-for-photon.0.rc3.html" /><category term="release" /><category term="jbosstools" /><category term="devstudio" /><category term="jbosscentral" /><author><name>jeffmaury</name></author><id>https://tools.jboss.org/blog/4.6.0.am3-for-photon.0.rc3.html</id><updated>2018-06-20T06:26:08Z</updated><published>2018-06-19T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Happy to announce 4.6.0.AM3 (Developer Milestone 3) build for Eclipse Photon.0.RC3.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Downloads available at &lt;a href="https://tools.jboss.org/downloads/jbosstools/photon/4.6.0.AM3.html"&gt;JBoss Tools 4.6.0 AM3&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is New?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Full info is at &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.6.0.AM3.html"&gt;this page&lt;/a&gt;. Some highlights are below.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="general"&gt;&lt;a class="anchor" href="#general"&gt;&lt;/a&gt;General&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="eclipse-photon"&gt;&lt;a class="anchor" href="#eclipse-photon"&gt;&lt;/a&gt;Eclipse Photon&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;JBoss Tools is now targeting Eclipse Photon RC3.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="fuse-tooling"&gt;&lt;a class="anchor" href="#fuse-tooling"&gt;&lt;/a&gt;Fuse Tooling&lt;/h3&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="camel-uri-completion-with-xml-dsl"&gt;&lt;a class="anchor" href="#camel-uri-completion-with-xml-dsl"&gt;&lt;/a&gt;Camel URI completion with XML DSL&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As announced &lt;a href="https://developers.redhat.com/blog/2018/01/31/apache-camel-uri-completion-eclipse-xml-editor/"&gt;here&lt;/a&gt;, it was already possible to have Camel URI completion with XML DSL in the source tab of the Camel Route editor by installing the &lt;a href="https://github.com/camel-tooling/camel-lsp-client-eclipse"&gt;Language Support for Apache Camel&lt;/a&gt; in your IDE.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This feature is now installed by default with Fuse Tooling!&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/fusetools/images/completionSourceEditor.gif" alt="Camel URI completion in source tab of Camel Editor" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Now you have the choice to use the properties view with UI help to configure Camel components or to use the source editor and benefit from completion features. It all depends on your development preferences!&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="webservices-tooling"&gt;&lt;a class="anchor" href="#webservices-tooling"&gt;&lt;/a&gt;Webservices Tooling&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="jax-rs-2-1-support"&gt;&lt;a class="anchor" href="#jax-rs-2-1-support"&gt;&lt;/a&gt;JAX-RS 2.1 Support&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;JAX-RS 2.1 is part of JavaEE8 and JBoss Tools now provides you with support for this update of the specification.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="server-side-events"&gt;&lt;a class="anchor" href="#server-side-events"&gt;&lt;/a&gt;Server side events&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;JAX-RS 2.1 brought support for server side events. The &lt;code&gt;Sse&lt;/code&gt; and &lt;code&gt;SseEventSink&lt;/code&gt; resources can now be injected into method arguments thanks to the @Context annotation.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Jeff Maury&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/jtOEkqNA9Q8" height="1" width="1" alt=""/&gt;</content><summary>Happy to announce 4.6.0.AM3 (Developer Milestone 3) build for Eclipse Photon.0.RC3. Downloads available at JBoss Tools 4.6.0 AM3. What is New? Full info is at this page. Some highlights are below. General Eclipse Photon JBoss Tools is now targeting Eclipse Photon RC3. Fuse Tooling Camel URI completion with XML DSL As announced here, it was already possible to have Camel URI completion with XML DSL in the source tab of the Camel Route editor by installing the Language Support for Apache Camel in your IDE. This feature is now installed by default with Fuse Tooling! Now you have the choice to use the properties view with UI help to configure Camel...</summary><dc:creator>jeffmaury</dc:creator><dc:date>2018-06-19T00:00:00Z</dc:date><feedburner:origLink>https://tools.jboss.org/blog/4.6.0.am3-for-photon.0.rc3.html</feedburner:origLink></entry><entry><title>Official Apache Camel branded swags available for sale</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7BRVtyIuTpE/official-apache-camel-branded-swags.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-official_apache_camel_branded_swags_available_for_sale</id><updated>2018-06-18T07:39:36Z</updated><published>2018-06-18T07:39:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Hi Cameleers,&lt;br /&gt;&lt;br /&gt;with great joy I'm happy to announce that Camel branded swag:&lt;br /&gt;T-Shirts, Cases, Posters, Mugs, Notebooks and a whole lot more, is&lt;br /&gt;available at the official Apache Software Foundation store at Redbubble.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://www.redbubble.com/people/comdev/works/32232604-apache-camel?asc=u"&gt;&lt;img border="0" data-original-height="425" data-original-width="678" height="200" src="https://2.bp.blogspot.com/-AxKCyGXa8cE/Wydgokc-iqI/AAAAAAAABos/OFfKX7oZg2EpC-GFQJT_nl89ZJzsnmpwwCEwYBhgL/s320/swag-store.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;The store is here:&lt;br /&gt;&lt;a href="https://www.redbubble.com/people/comdev/works/32232604-apache-camel?asc=u"&gt;https://www.redbubble.com/people/comdev/works/32232604-apache-camel?asc=u&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;From any purchases you make a percentage goes as a donation to the ASF.&lt;br /&gt;&lt;br /&gt;Thanks to Zoran Regvart whom helped us get the Camel swags into the Apache store.&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=Wk7xgi0KwBY:4mScTUiLT_Q:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=Wk7xgi0KwBY:4mScTUiLT_Q:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=Wk7xgi0KwBY:4mScTUiLT_Q:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=Wk7xgi0KwBY:4mScTUiLT_Q:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=Wk7xgi0KwBY:4mScTUiLT_Q:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=Wk7xgi0KwBY:4mScTUiLT_Q:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=Wk7xgi0KwBY:4mScTUiLT_Q:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/Wk7xgi0KwBY" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7BRVtyIuTpE" height="1" width="1" alt=""/&gt;</content><summary>Hi Cameleers, with great joy I'm happy to announce that Camel branded swag: T-Shirts, Cases, Posters, Mugs, Notebooks and a whole lot more, is available at the official Apache Software Foundation store at Redbubble. The store is here: https://www.redbubble.com/people/comdev/works/32232604-apache-camel?asc=u From any purchases you make a percentage goes as a donation to the ASF. Thanks to Zoran Reg...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2018-06-18T07:39:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/Wk7xgi0KwBY/official-apache-camel-branded-swags.html</feedburner:origLink></entry><entry><title>Red Hat Single Sign-On in Keynote demo on Red Hat Summit!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/keYdteRKPD4/red-hat-single-sign-on-in-keynote-demo.html" /><category term="feed_group_name_keycloak" scheme="searchisko:content:tags" /><category term="feed_name_keycloak" scheme="searchisko:content:tags" /><author><name>Marek Posolda</name></author><id>searchisko:content:id:jbossorg_blog-red_hat_single_sign_on_in_keynote_demo_on_red_hat_summit</id><updated>2018-06-18T06:59:53Z</updated><published>2018-06-18T06:59:00Z</published><content type="html">&lt;p&gt;Red Hat Summit is one of the most important events during the year. Many geeks, Red Hat employees and customers have great opportunity to meet, learn new things and attend lots of interesting presentations and trainings. During the summit this year, there were few breakout sessions, which were solely about Keycloak and Red Hat SSO. You can take a look at &lt;a href="http://blog.keycloak.org/2018/05/red-hat-single-sign-on-red-hat-summit.html"&gt;this blogpost&lt;/a&gt; for more details. &lt;p&gt;One of the most important parts of Red Hat Summit are Keynote demos, which show the main bullet points and strategies going forward. Typically they also contain the demos of the most interesting technologies, which Red Hat uses. &lt;p&gt;On the Thursday morning keynote, there was &lt;a href="https://www.youtube.com/watch?v=hu2BmE1Wk_Q&amp;feature=youtu.be&amp;t=385"&gt;this demo&lt;/a&gt; to show the Hybrid Cloud with 3 clouds (Azure, Amazon, Private) in action! There were many technologies and interesting projects involved. Among others, let's name &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/data-grid"&gt;Red Hat JBoss Data Grid (JDG)&lt;/a&gt;, &lt;a href="https://openwhisk.apache.org/"&gt;OpenWhisk&lt;/a&gt; or &lt;a href="https://www.gluster.org/"&gt;Gluster FS&lt;/a&gt;. The &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;RH-SSO&lt;/a&gt; (Red Hat product based on Keycloak project) had a honor to be used as well. &lt;h2&gt;Red Hat SSO setup details&lt;/h2&gt; &lt;p&gt;The frontend of the demo was the simple mobile game. RH-SSO was used at the very first stage to authenticate users to the mobile game. Each attendee had an opportunity to try it by yourself. In total, we had 1200 players of the game. &lt;p&gt;There was loadbalancer up-front and every user was automatically forwarded to one of the 3 clouds. The mobile application used &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.2/html/securing_applications_and_services_guide/openid_connect_3#javascript_adapter"&gt;RH-SSO Javascript adapter&lt;/a&gt; (keycloak.js) to communicate with RH-SSO. &lt;p&gt;With Javascript application, whole OpenID Connect login flow happens within browser and hence can rely on sticky session. So since Javascript adapter is used, you may think that we can do just "easy" setup and let the RH-SSO instances across all 3 clouds to be independent of each other and have each of them to use separate RDBMS and infinispan caches. See the image below for what such a setup would look like: &lt;p&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-vL-5tH6jujE/WydSVbwO65I/AAAAAAAANno/0QEoU2PQyzYBJMFAQkBiE4O6O_345JhkwCPcBGAYYCw/s1600/cross-dc-blog-architecture-rhsso.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" src="https://2.bp.blogspot.com/-vL-5tH6jujE/WydSVbwO65I/AAAAAAAANno/0QEoU2PQyzYBJMFAQkBiE4O6O_345JhkwCPcBGAYYCw/s1600/cross-dc-blog-architecture-rhsso.png" data-original-width="512" data-original-height="788" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;With this setup, every cloud is aware just about the users and sessions created on itself. This is fine with sticky session, but it won’t work for failover scenarios in case if one of the 3 clouds is broken/removed. There are also other issues with it - for example that admins and users see just sessions created on particular cloud. There are also potential security issues. For example when admin disables user on one cloud, user would still be enabled on other clouds as changes to user won’t be propagated to other clouds. &lt;p&gt;So we rather want to show more proper setup aware of the replication. Also because one part of the demo was showing failover in action. One of the 3 clouds (Amazon) was killed and users, who were previously logged in Amazon, were redirected to one of the remaining 2 clouds. The point was that the end user won't be able to recognize any change. Hence users previously logged in Amazon must be still able to refresh their tokens in Azure or Private cloud. This in turn meant that the data (both users, user sessions and caches) need to be aware of all 3 clouds. &lt;p&gt;In Keycloak 3.X, we added support for &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.2/html/server_installation_and_configuration_guide/operating-mode#crossdc-mode"&gt;Cross-datacenter (Cross-site) setup&lt;/a&gt; with usage of external JDG servers to replicate data among datacenters (tech preview in RH-SSO 7.2). The demo was using exactly this setup. Each site had JDG server and all 3 sites communicate with each other through those JDG servers. This is standard JDG Cross-DC setup. See the picture below for what the demo looked like: &lt;p&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-nBIDom2q4zI/WydUZMN_5DI/AAAAAAAANnw/95OlEmQMfQsZ98RBsv8t-twA8GtrGYbhgCLcBGAs/s1600/cross-dc-blog-actual-setup-architecture-rhsso.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" src="https://3.bp.blogspot.com/-nBIDom2q4zI/WydUZMN_5DI/AAAAAAAANnw/95OlEmQMfQsZ98RBsv8t-twA8GtrGYbhgCLcBGAs/s1600/cross-dc-blog-actual-setup-architecture-rhsso.png" data-original-width="727" data-original-height="789" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;The JDG servers were not used during the demo just for the purpose of the RH-SSO, but also for the purpose of other parts of the demo. The details are described in the other blog by Sebastian Laskawiec. The JDG servers were setup with ASYNC backups, which was more effective and was completely fine for the purpose of the demo due the fact that mobile application was using keycloak.js adapter. See &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.2/html/server_installation_and_configuration_guide/operating-mode#backups"&gt;RH-SSO docs&lt;/a&gt; for more details. &lt;h2&gt;Red Hat SSO customizations&lt;/h2&gt; &lt;p&gt;The RH-SSO was using standard &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_middleware_for_openshift/3/html/red_hat_single_sign-on_for_openshift/"&gt;RH-SSO openshift image&lt;/a&gt; . For Cross-DC setup, we needed to do configuration changes as described in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.2/html/server_installation_and_configuration_guide/operating-mode#crossdc-mode"&gt;RHSSO documentation&lt;/a&gt; . Also few other customizations were done. &lt;h3&gt;JDG User Storage&lt;/h3&gt; &lt;p&gt;RH-SSO Cross-DC setup currently requires both replicated RDBMS and replicated JDG server. When preparing to demo, we figured that using the clustered RDBMS in OpenShift replicated across all 3 clouds, is not very straightforward thing to setup. &lt;p&gt;Fortunately RH-SSO is highly customizable platform and among other things, it provides supported &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.2/html/server_administration_guide/user-storage-federation"&gt;User Storage SPI&lt;/a&gt; , which allows customers to plug their own storage for RH-SSO users. So instead of setup of replicated RDBMS, we created custom JDG User Storage. So users of the example realm were saved inside JDG instead of the RDBMS Database. &lt;p&gt;Lessons learned is, that we want to make the Keycloak/RH-SSO Cross-DC setup simpler for administrators. Hence we're considering removing the need for replicated RDBMS entirely and instead store all realms and users metadata within JDG. So just replicated JDG would be a requirement for Cross-DC setup. &lt;h3&gt;Other customizations&lt;/h3&gt; &lt;p&gt;For the purpose of the demo, we did custom login theme. We also did Email-Only authenticator, which allows to register user just by providing their email address. This is obviously not very secure, but it's pretty neat for the example purpose. Keynote users were also able to login with &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_single_sign-on/7.2/html/server_administration_guide/identity_broker#google"&gt;Google Identity Provider&lt;/a&gt; or &lt;a href="https://developers.redhat.com/"&gt;Red Hat Developers OpenID Connect Identity Provider&lt;/a&gt;, which was useful for users, who already had an account in those services. &lt;p&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-Ge7V9OICypw/WydV-ODGNmI/AAAAAAAANn8/H7EmDQ4SfQshbawCjIpkKISnM6ZwW2QrACLcBGAs/s1600/login-screen.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" src="https://2.bp.blogspot.com/-Ge7V9OICypw/WydV-ODGNmI/AAAAAAAANn8/H7EmDQ4SfQshbawCjIpkKISnM6ZwW2QrACLcBGAs/s1600/login-screen.png" data-original-width="1600" data-original-height="857" /&gt;&lt;/a&gt;&lt;/div&gt; &lt;p&gt;If you want to try all these things in action, you can try to checkout our &lt;a href="https://github.com/rhdemo/rh-sso"&gt;Demo Project on Github&lt;/a&gt; and deploy it to your own openshift cluster! If you have 3 clouds, even better! You can try the full setup including JDG to try exactly the setup we used during keynote demo.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/keYdteRKPD4" height="1" width="1" alt=""/&gt;</content><summary>Red Hat Summit is one of the most important events during the year. Many geeks, Red Hat employees and customers have great opportunity to meet, learn new things and attend lots of interesting presentations and trainings. During the summit this year, there were few breakout sessions, which were solely about Keycloak and Red Hat SSO. You can take a look at this blogpost for more details. One of the ...</summary><dc:creator>Marek Posolda</dc:creator><dc:date>2018-06-18T06:59:00Z</dc:date><feedburner:origLink>http://blog.keycloak.org/2018/06/red-hat-single-sign-on-in-keynote-demo.html</feedburner:origLink></entry><entry><title>New: Asynchronous container filters</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/4q7RjLd5rj4/new-asynchronous-container-filters" /><category term="feed_group_name_resteasy" scheme="searchisko:content:tags" /><category term="feed_name_resteasy" scheme="searchisko:content:tags" /><author><name>Stephane Epardaud</name></author><id>searchisko:content:id:jbossorg_blog-new_asynchronous_container_filters</id><updated>2018-06-18T04:03:55Z</updated><published>2018-06-18T04:03:55Z</published><content type="html">&lt;!-- [DocumentBodyStart:4708eeb8-6e56-4321-a441-65e791e31ff6] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;JAX-RS 2.0 shipped with support for filtering &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/ContainerRequestFilter.html" rel="nofollow"&gt;requests&lt;/a&gt; and &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/ContainerResponseFilter.html" rel="nofollow"&gt;responses&lt;/a&gt;, which enabled a lot of great use-cases for delegating duplicated code away from resources and into filters that would do the same processing for every resource method.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Request filters work by overriding the &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/ContainerRequestFilter.html#filter-javax.ws.rs.container.ContainerRequestContext-" rel="nofollow"&gt;ContainerRequestFilter.filter&lt;/a&gt; method and observe or modify the given &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/ContainerRequestContext.html" rel="nofollow"&gt;context&lt;/a&gt; object, or &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/ContainerRequestContext.html#abortWith-javax.ws.rs.core.Response-" rel="nofollow"&gt;abort the filter chain&lt;/a&gt; with a response if the filter already has a response and the other filters and resource method are not required. Simply returning from the filter method will cause the next filter to be called, or when we have run all the filters, it will invoke the resource method.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Response filters are very similar, but &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/ContainerResponseFilter.html" rel="nofollow"&gt;execute&lt;/a&gt; after the resource method has been executed and &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/ContainerResponseContext.html" rel="nofollow"&gt;produced an entity, status code, headers&lt;/a&gt;, which the filter can then modify if required, or simply return to let the next filters run, or the response be sent to the client.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;This is all great, but how does it work in an asynchronous ecosystem ? It doesn't, really, because even though JAX-RS supports &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/Suspended.html" rel="nofollow"&gt;suspending the request&lt;/a&gt;, it only supports it within the resource method: filters are too early (for request filters), or too late (for response filters).&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;In RESTEasy 3.5 and 4.0.0, we introduced the ability to &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/userguide/html/Interceptors.html#d4e1819" rel="nofollow"&gt;suspend the request in filters&lt;/a&gt;. To do that, write your request or response filter as usual, but then cast your context object down to &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/javadocs/org/jboss/resteasy/core/interception/jaxrs/SuspendableContainerRequestContext.html" rel="nofollow"&gt;SuspendableContainerRequestContext&lt;/a&gt; or &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/javadocs/org/jboss/resteasy/core/interception/jaxrs/SuspendableContainerResponseContext.html" rel="nofollow"&gt;SuspendableContainerResponseContext&lt;/a&gt; (for response filters), and you can then:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;- suspend the request with &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/javadocs/org/jboss/resteasy/core/interception/jaxrs/SuspendableContainerRequestContext.html#suspend--" rel="nofollow"&gt;SuspendableContainerRequestContext.suspend()&lt;/a&gt;&lt;/p&gt;&lt;p&gt;- resume it normally with &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/javadocs/org/jboss/resteasy/core/interception/jaxrs/SuspendableContainerRequestContext.html#resume--" rel="nofollow"&gt;SuspendableContainerRequestContext.resume()&lt;/a&gt;, to proceed to the next filter or resource method&lt;/p&gt;&lt;p&gt;- resume it with a response with the standard &lt;a class="jive-link-external-small" href="https://docs.oracle.com/javaee/7/api/javax/ws/rs/container/ContainerRequestContext.html#abortWith-javax.ws.rs.core.Response-" rel="nofollow"&gt;ContainerRequestContext.abortWith()&lt;/a&gt;, to directly send that response to the client&lt;/p&gt;&lt;p&gt;- resume it with an exception with &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/javadocs/org/jboss/resteasy/core/interception/jaxrs/SuspendableContainerRequestContext.html#resume-java.lang.Throwable-" rel="nofollow"&gt;SuspendableContainerRequestContext.resume(Throwable)&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Similarly, for response filters, you can:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;- suspend the request with &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/javadocs/org/jboss/resteasy/core/interception/jaxrs/SuspendableContainerResponseContext.html#suspend--" rel="nofollow"&gt;SuspendableContainerResponseContext.suspend()&lt;/a&gt;&lt;/p&gt;&lt;p&gt;- resume it normally with &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/javadocs/org/jboss/resteasy/core/interception/jaxrs/SuspendableContainerResponseContext.html#resume--" rel="nofollow"&gt;SuspendableContainerResponseContext.resume()&lt;/a&gt;, to proceed to the next filter or return the response to the client&lt;/p&gt;&lt;p&gt;- resume it with an exception with &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.0.Final/javadocs/org/jboss/resteasy/core/interception/jaxrs/SuspendableContainerResponseContext.html#resume-java.lang.Throwable-" rel="nofollow"&gt;SuspendableContainerResponseContext.resume(Throwable)&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Of course, the &lt;span style="font-family: 'andale mono', times;"&gt;resume()&lt;/span&gt; methods only work after you've called &lt;span style="font-family: 'andale mono', times;"&gt;suspend()&lt;/span&gt;, but otherwise you can call &lt;span style="font-family: 'andale mono', times;"&gt;resume()&lt;/span&gt; right after &lt;span style="font-family: 'andale mono', times;"&gt;suspend()&lt;/span&gt;, before returning from the filter, in which case the request will not even be made asynchronous, or you can call &lt;span style="font-family: 'andale mono', times;"&gt;resume()&lt;/span&gt; later after you return from the method, or even from another thread entirely, in which case the request will become asynchronous.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The fact that filters may turn requests asynchronous has no impact at all on the rest of your code: non-asynchronous and asynchronous resource methods continue to work exactly as normal, regardless of the asynchronous status of the request, so you don't need to modify your code to accommodate for asynchronous filters.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h3&gt;Asynchronous rate-limiter example with Redis&lt;/h3&gt;&lt;h3&gt;&lt;/h3&gt;&lt;p&gt;Asynchronous filters are useful for plugging in anything that requires asynchrony, such as reactive security frameworks, async response processing or async caching. We will illustrate how to use asynchronous filters with a rate-limiter example.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;For that, we will use &lt;a class="jive-link-external-small" href="https://github.com/mokies/ratelimitj/tree/master/ratelimitj-redis" rel="nofollow"&gt;RateLimitJ for Redis&lt;/a&gt;, which uses Redis to store rate-limiting information for your API. This is very useful for sharing rate-limit between your API server cluster, because you can store that info in a Redis cluster, and you don't have to worry about blocking clients while you're waiting for Redis to give you the info: you just become asynchronous until you have an answer from Redis.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;We will first import the right Maven dependency for RateLimitJ:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:16745537-bb02-4f39-a550-831dbd42ec31][excluded]--&gt;&lt;pre class="xml" name="code"&gt;&amp;lt;dependency&amp;gt; &amp;#160; &amp;lt;groupId&amp;gt;es.moki.ratelimitj&amp;lt;/groupId&amp;gt; &amp;#160; &amp;lt;artifactId&amp;gt;ratelimitj-redis&amp;lt;/artifactId&amp;gt; &amp;#160; &amp;lt;version&amp;gt;0.4.2&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &lt;/pre&gt;&lt;!--[CodeBlockEnd:16745537-bb02-4f39-a550-831dbd42ec31]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;And let's not forget to &lt;a class="jive-link-external-small" href="https://redis.io/download" rel="nofollow"&gt;install and run a local Redis cluster&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;We will start by declaring a &lt;span style="font-family: 'andale mono', times;"&gt;@RateLimit&lt;/span&gt; annotation that we can use on our resource methods or classes to indicate we want rate limiting:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:8f1f7376-90ee-4b7b-9e55-e1ea73653c26][excluded]--&gt;&lt;pre class="java" name="code"&gt;@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.TYPE, ElementType.METHOD}) public @interface RateLimit { /** * Number of {@link #unit()} that defines our sliding window. */ int duration(); /** * Unit used for the sliding window {@link #duration()}. */ TimeUnit unit(); /** * Maximum number of requests to allow during our sliding window. */ int maxRequest(); }&lt;/pre&gt;&lt;!--[CodeBlockEnd:8f1f7376-90ee-4b7b-9e55-e1ea73653c26]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;And we have to declare a &lt;span style="font-family: 'andale mono', times;"&gt;DynamicFeature&lt;/span&gt; that enables the filter on annotated methods and classes:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:5fe56e1e-a859-4969-a26a-7ec0ad514570][excluded]--&gt;&lt;pre class="java" name="code"&gt;@Provider public class RateLimitFeature implements DynamicFeature { &amp;#160; private StatefulRedisConnection&amp;lt;string,string&amp;gt; connection; &amp;#160; public RateLimitFeature(){ &amp;#160;&amp;#160;&amp;#160; // connect to the local Redis &amp;#160;&amp;#160;&amp;#160; connection = RedisClient.create("redis://localhost").connect(); &amp;#160; } &amp;#160; public void configure(ResourceInfo resourceInfo, FeatureContext context) { &amp;#160;&amp;#160;&amp;#160; // See if we're rate-limiting &amp;#160;&amp;#160;&amp;#160; RateLimit limit = resourceInfo.getResourceMethod().getAnnotation(RateLimit.class); &amp;#160;&amp;#160;&amp;#160; if(limit == null) &amp;#160;&amp;#160;&amp;#160; limit = resourceInfo.getResourceClass().getAnnotation(RateLimit.class); &amp;#160;&amp;#160;&amp;#160; if(limit != null) { &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; // add the rate-limiting filter &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; Set rules = new HashSet&amp;lt;&amp;gt;(); &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; rules.add(RequestLimitRule.of(limit.duration(), limit.unit(), limit.maxRequest())); &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; context.register(new RateLimitFilter(new RedisSlidingWindowRequestRateLimiter(connection, rules))); &amp;#160;&amp;#160;&amp;#160; } &amp;#160; } }&lt;/pre&gt;&lt;!--[CodeBlockEnd:5fe56e1e-a859-4969-a26a-7ec0ad514570]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;And this is how we implement our asynchronous filter:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:d1b0ec64-85b3-4ed3-aede-0ee6727ece97][excluded]--&gt;&lt;pre class="java" name="code"&gt;public class RateLimitFilter implements ContainerRequestFilter { &amp;#160; private RedisSlidingWindowRequestRateLimiter requestRateLimiter; &amp;#160; public RateLimitFilter(RedisSlidingWindowRequestRateLimiter requestRateLimiter) { &amp;#160;&amp;#160;&amp;#160; this.requestRateLimiter = requestRateLimiter; &amp;#160; } &amp;#160; public void filter(ContainerRequestContext requestContext) throws IOException { &amp;#160;&amp;#160;&amp;#160; // Get access to the remote address &amp;#160;&amp;#160;&amp;#160; HttpServletRequest servletRequestContext = ResteasyProviderFactory.getContextData(HttpServletRequest.class); &amp;#160;&amp;#160;&amp;#160; // Suspend the request &amp;#160;&amp;#160;&amp;#160; SuspendableContainerRequestContext suspendableRequestContext = (SuspendableContainerRequestContext) requestContext; &amp;#160;&amp;#160;&amp;#160; suspendableRequestContext.suspend(); &amp;#160;&amp;#160;&amp;#160; // Query and increment by remote IP &amp;#160;&amp;#160;&amp;#160; requestRateLimiter.overLimitAsync("ip:"+servletRequestContext.getRemoteAddr()) &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; .whenComplete((overlimit, error) -&amp;gt; { &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; // Error case &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; if(error != null) &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; suspendableRequestContext.resume(error); &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; // Over limit &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; else if(overlimit) &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; suspendableRequestContext.abortWith(Response.status(429).build()); &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; // Good to go! &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; else &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; suspendableRequestContext.resume(); &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; }); &amp;#160; } }&lt;/pre&gt;&lt;!--[CodeBlockEnd:d1b0ec64-85b3-4ed3-aede-0ee6727ece97]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p&gt;Now all we have left to do is to implement a resource with rate-limiting:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:4d3b4c7c-0590-48cc-9645-9a51f0a00ce5][excluded]--&gt;&lt;pre class="java" name="code"&gt;@Path("/") public class Resource { &amp;#160; @Path("free") &amp;#160; @GET &amp;#160; public String free() { &amp;#160;&amp;#160;&amp;#160; return "Hello Free World"; &amp;#160; } &amp;#160; @RateLimit(duration = 10, unit = TimeUnit.SECONDS, maxRequest = 2) &amp;#160; @Path("limited") &amp;#160; @GET &amp;#160; public String limited() { &amp;#160;&amp;#160;&amp;#160; return "Hello Limited World"; &amp;#160; } }&lt;/pre&gt;&lt;!--[CodeBlockEnd:4d3b4c7c-0590-48cc-9645-9a51f0a00ce5]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;If you go to &lt;span style="font-family: 'andale mono', times;"&gt;/free&lt;/span&gt; you will get an unlimited number of requests, while if you go to &lt;span style="font-family: 'andale mono', times;"&gt;/limited&lt;/span&gt; you will get two requests allowed every 10 seconds. The rest of the time you will get an HTTP response of &lt;a class="jive-link-external-small" href="https://tools.ietf.org/html/rfc6585#section-4" rel="nofollow"&gt;Too Many Requests (429)&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;If you have the need for &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.5.1.Final/userguide/html/Interceptors.html#d4e1831" rel="nofollow"&gt;asynchronous request or response filters&lt;/a&gt;, don't hesitate to give RESTEasy &lt;span style="font-family: 'andale mono', times;"&gt;3.5.1.Final&lt;/span&gt; or &lt;span style="font-family: 'andale mono', times;"&gt;4.0.0.Beta2&lt;/span&gt; a try.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:4708eeb8-6e56-4321-a441-65e791e31ff6] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/4q7RjLd5rj4" height="1" width="1" alt=""/&gt;</content><summary>JAX-RS 2.0 shipped with support for filtering requests and responses, which enabled a lot of great use-cases for delegating duplicated code away from resources and into filters that would do the same processing for every resource method.   Request filters work by overriding the ContainerRequestFilter.filter method and observe or modify the given context object, or abort the filter chain with a res...</summary><dc:creator>Stephane Epardaud</dc:creator><dc:date>2018-06-18T04:03:55Z</dc:date><feedburner:origLink>https://developer.jboss.org/community/resteasy/blog/2018/06/18/new-asynchronous-container-filters</feedburner:origLink></entry><entry><title>Jakarta EE and OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gPNg-VgmQO4/jakarta-ee-and-openshift" /><category term="devnation" scheme="searchisko:content:tags" /><category term="feed_group_name_management" scheme="searchisko:content:tags" /><category term="feed_name_marklittle" scheme="searchisko:content:tags" /><category term="jakarta ee" scheme="searchisko:content:tags" /><category term="microprofile" scheme="searchisko:content:tags" /><category term="red hat summit" scheme="searchisko:content:tags" /><author><name>Mark Little</name></author><id>searchisko:content:id:jbossorg_blog-jakarta_ee_and_openshift</id><updated>2018-06-17T13:09:21Z</updated><published>2018-06-17T13:09:00Z</published><content type="html">&lt;!-- [DocumentBodyStart:ff43464a-cfdb-4a85-bd0e-e6a6de73bdda] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;At &lt;a class="jive-link-external-small" href="https://www.redhat.com/en/summit/2018" rel="nofollow"&gt;Summit&lt;/a&gt; this year I was able to meet with a number of our key customers and partners. I was also there to give a presentation with Dimitris on &lt;a class="jive-link-external-small" href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=153822" rel="nofollow"&gt;the future of enterprise Java&lt;/a&gt;, which was based a bit on an earlier &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2018/05/02/devnation-jakarta-ee-the-future-of-java-ee/" rel="nofollow"&gt;DevNation Live&lt;/a&gt; session I gave. Now at the time I submitted the session I had no idea which customers would be there in San Francisco but it's always interesting to see how these things turn out because they came together very fortuitously. During the presentation we spoke about Jakarra EE and how it should bring together the Java communities to drive the evolution of enterprise Java towards cloud native. There was a lot of interest in the audience but it was afterwards that I probably had my most beneficial engagements with customers and analysts on the topic. The common thread with all of these meetings was that they had so-called monoliths and worried that they were being left behind by their competitors who were moving to microservices. Or so they believed.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;If you are a student of history you may know about the early cold war where the US thought the USSR had huge stockpiles of nuclear weapons and used that belief to drive their own weapons plans, when in reality the USSR had very few and were just as ill informed as the Americans. I see the same with microservices: everyone believes they understand them, everyone worries their competitors are using them to get ahead and everyone wants them, when in reality they are fine with what they have or they don't need to move quite so quickly towards a new microservices architecture. But how does this play with the future of enterprise Java and specifically &lt;a class="jive-link-blog-small" data-containerId="1427" data-containerType="37" data-objectId="6170" data-objectType="38" href="https://developer.jboss.org/blogs/mark.little/2018/02/28/jakarta-ee-onward"&gt;Jakarta EE&lt;/a&gt;? Well the aim with this industry wide effort is to allow developers to evolve their implementations (monoliths) towards more cloud native, agile implementations using microservices just as we have been doing with &lt;a class="jive-link-external-small" href="http://wildfly-swarm.io/" rel="nofollow"&gt;Eclipse MicroProfile&lt;/a&gt; based on Java EE. At their own pace. Using the skills their teams have built up over nearly two decades. Not throwing away experience but building upon it! Making data driven decisions based upon the needs to customers and their own developers. And if we can do this through the power of open source then let's add another benefit: collaboratively.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;This was a key thing that the audience came away with and which our customers latched onto: don't throw away all you have learned and which works but build on it, evolve it. Evolve the people and processes as much as the software. That can give you the advantage over your competition if they are having to adopt entirely new stacks or frameworks or languages. Your advantage isn't in the software but in the people who developed it and know how your business works and why! Retaining them and their skills are key. They are the assets which cannot be obtained by contractors or consultants.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Another thing which may not be immediately apparent is that Jakarta EE is a prime example of what &lt;a class="jive-link-external-small" href="http://www.tom-ridge.com/2015-09-11_richard_hamming_1968_turing_award_lecture_quote.html" rel="nofollow"&gt;Hamming&lt;/a&gt; was taking about in his Turing Award speech by building on the shoulders of giants rather than reinventing the wheel: so much real world experience has defined the landscape of enterprise Java, of which Java EE plays a key part, and we don't want to lose that experience or the mature implementations based upon it. We want new systems to be as stable and reliable as old and to accomplish that we need many of the skilled developers and a lot of the software! Jakarta EE offers the best path forward for both!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Now while no Jakarta EE implementations yet exist we do have some work that is relevant. There's WildFly Swarm for a start and then of course there's EAP. Both available through &lt;a class="jive-link-external-small" href="https://developers.redhat.com/products/rhoar/overview/" rel="nofollow"&gt;RHOAR&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:ff43464a-cfdb-4a85-bd0e-e6a6de73bdda] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gPNg-VgmQO4" height="1" width="1" alt=""/&gt;</content><summary>At Summit this year I was able to meet with a number of our key customers and partners. I was also there to give a presentation with Dimitris on the future of enterprise Java, which was based a bit on an earlier DevNation Live session I gave. Now at the time I submitted the session I had no idea which customers would be there in San Francisco but it's always interesting to see how these things tur...</summary><dc:creator>Mark Little</dc:creator><dc:date>2018-06-17T13:09:00Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/mark.little/2018/06/17/jakarta-ee-and-openshift</feedburner:origLink></entry><entry><title>jBPM 7.8 native execution of BPMN2, DMN 1.1 and CMMN 1.1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7zMguQyzoSs/jbpm-78-native-execution-of-bpmn2-dmn.html" /><category term="case_cmmn" scheme="searchisko:content:tags" /><category term="case_mgmt" scheme="searchisko:content:tags" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><category term="jbpm_7.8" scheme="searchisko:content:tags" /><category term="jbpm_bpmn2" scheme="searchisko:content:tags" /><category term="jbpm_cases" scheme="searchisko:content:tags" /><category term="jbpm_cmmn" scheme="searchisko:content:tags" /><category term="jbpm_dmn" scheme="searchisko:content:tags" /><author><name>Maciej Swiderski</name></author><id>searchisko:content:id:jbossorg_blog-jbpm_7_8_native_execution_of_bpmn2_dmn_1_1_and_cmmn_1_1</id><updated>2018-06-15T12:58:28Z</updated><published>2018-06-15T12:58:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;with upcoming 7.8 release of jBPM there is quite nice thing to announce - native execution of:&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;BPMN2 - was there already for many years&lt;/li&gt;&lt;li&gt;DMN 1.1 - from the early days of version 7&lt;/li&gt;&lt;li&gt;CMMN 1.1 - comes with version 7.8&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;The biggest thing coming with 7.8 is actually CMMN execution. It is mainly added for completeness of the execution so people who would like to model case with CMMN can actually execute that directly on jBPM (via KIE Server or embedded).&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Although jBPM supports now CMMN, it is still recommended to use BPMN2 and case management features of jBPM for advanced cases to benefit from features that both specification brings rather to be limited to particular approach. Nevertheless CMMN can be a good visualisation for less complex cases where data and loosely coupled activities can build a good business view.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;i&gt;Disclaimer: jBPM currently does not provide nor plans to provide any modelling capabilities for CMMN.&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;With that said let's take a quick look at what is supported from the CMMN specification as obviously it's not covering 100% of the spec.&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;tasks (human task, process task, decision task, case task)&lt;/li&gt;&lt;li&gt;discretionary tasks (same as above)&lt;/li&gt;&lt;li&gt;stages&lt;/li&gt;&lt;li&gt;milestones&lt;/li&gt;&lt;li&gt;case file items&lt;/li&gt;&lt;li&gt;sentries (both entry and exit)&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;div&gt;Not all attributes of tasks are supported - required, repeat and manual activation are currently not supported. Although most of the behaviour can still be achieved using different constructs.&lt;/div&gt;&lt;div&gt;Sentries for individual tasks are limited to entry criteria while entry and exit are supported for stages and milestones.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Decision task by default maps to DMN decision although ruleflow group based is also possible with simplified syntax - decisionRef should be set to ruleflow-group attribute.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Event listeners are not supported as they do not bring much value for execution and instead CaseEventListener support in jBPM should be used as substitute.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Let's have a quick look at how the sample Order IT case would look like designed in CMMN&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-YDMiMFfpR1w/WyOvBRxMgfI/AAAAAAAABdg/d8DiMkhLlcUzJa9_6hVNr4SN9ZbYYSDjQCLcBGAs/s1600/Screen%2BShot%2B2018-06-15%2Bat%2B14.07.45.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="727" data-original-width="1421" height="326" src="https://4.bp.blogspot.com/-YDMiMFfpR1w/WyOvBRxMgfI/AAAAAAAABdg/d8DiMkhLlcUzJa9_6hVNr4SN9ZbYYSDjQCLcBGAs/s640/Screen%2BShot%2B2018-06-15%2Bat%2B14.07.45.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;some might say it's less or more readable and frankly speaking it's just a matter of preferences.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Here is a screencast showing this CMMN model being executed&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/wYtsHUwCgWc" width="560"&gt;&lt;/iframe&gt; &lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Next I'd like to show the true power of jBPM - execution of all three types of models:&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;CMMN for top level case definition&lt;/li&gt;&lt;li&gt;DMN for decision service&lt;/li&gt;&lt;li&gt;BPMN2 for process execution&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;you can add all of them into kjar (via import asset in workbench) build, deploy from workbench directly to KIE Server and execute. So here are our assets&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;A case definition that has:&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;decision task that invokes DMN decision that calculates vacation days (Total Vacation Days)&lt;/li&gt;&lt;li&gt;two human tasks that are triggered based on the data (entry criterion)&lt;/li&gt;&lt;li&gt;process task that invokes BPMN2 process if the entry condition is met&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-GxcN8ZrhafQ/WyOwDdaXAOI/AAAAAAAABdo/rWJfD90-vWgRV1eqdk3AYVVn27DRzX9lQCLcBGAs/s1600/Screen%2BShot%2B2018-06-15%2Bat%2B14.08.12.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="722" data-original-width="881" height="522" src="https://2.bp.blogspot.com/-GxcN8ZrhafQ/WyOwDdaXAOI/AAAAAAAABdo/rWJfD90-vWgRV1eqdk3AYVVn27DRzX9lQCLcBGAs/s640/Screen%2BShot%2B2018-06-15%2Bat%2B14.08.12.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Here is our DMN model&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-Qz3ivqECBgQ/WyOwwBUXNwI/AAAAAAAABdw/rxA3p8JUbMM2ghWVz1ySBA_gnqOZkhCfwCLcBGAs/s1600/Screen%2BShot%2B2018-06-15%2Bat%2B14.08.33.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="607" data-original-width="1013" height="382" src="https://4.bp.blogspot.com/-Qz3ivqECBgQ/WyOwwBUXNwI/AAAAAAAABdw/rxA3p8JUbMM2ghWVz1ySBA_gnqOZkhCfwCLcBGAs/s640/Screen%2BShot%2B2018-06-15%2Bat%2B14.08.33.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;and last but not least is the BPMN2 process (actually the most simple one but still a valid process)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-v_3ZlVoIf9k/WyOw1bLDmcI/AAAAAAAABd0/nKyRaEZWIbgvWs7O76_sanMbfLcjEQgkQCLcBGAs/s1600/Screen%2BShot%2B2018-06-15%2Bat%2B14.09.10.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="272" data-original-width="606" height="286" src="https://1.bp.blogspot.com/-v_3ZlVoIf9k/WyOw1bLDmcI/AAAAAAAABd0/nKyRaEZWIbgvWs7O76_sanMbfLcjEQgkQCLcBGAs/s640/Screen%2BShot%2B2018-06-15%2Bat%2B14.09.10.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Another thing to mention is that, all the models where done with Tristotech Editors to illustrate that they can be simply created with another tool and imported into kjar for execution.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Here is another screencast showing this all step by step, from exporting from Tristotech, importing into workbench, building and deploying kjar and lastly execute on KIE Server.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/R2D7SFqTbNo" width="560"&gt;&lt;/iframe&gt; &lt;div&gt;&lt;br /&gt;That's all to share for now, 7.8 is just around the corner so keep your eyes open and visit &lt;a href="http://jbpm.org/"&gt;jbpm.org&lt;/a&gt; to learn more.&lt;br /&gt;&lt;br /&gt;And at the end here are the links to the projects (kjars) in github&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;a href="https://github.com/mswiderski/cmmn-itorders"&gt;CMMN Order IT case sample&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/mswiderski/cmmn-dmn-bpmn"&gt;CMMN, DMN, BPMN sample&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;Enjoy!&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7zMguQyzoSs" height="1" width="1" alt=""/&gt;</content><summary>with upcoming 7.8 release of jBPM there is quite nice thing to announce - native execution of: BPMN2 - was there already for many years DMN 1.1 - from the early days of version 7 CMMN 1.1 - comes with version 7.8 The biggest thing coming with 7.8 is actually CMMN execution. It is mainly added for completeness of the execution so people who would like to model case with CMMN can actually execute th...</summary><dc:creator>Maciej Swiderski</dc:creator><dc:date>2018-06-15T12:58:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/06/jbpm-78-native-execution-of-bpmn2-dmn.html</feedburner:origLink></entry><entry><title>Announcing .NET Core 2.1 for Red Hat Platforms</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/aUpfi5Mos60/" /><category term=".NET Core" /><category term="C#" /><category term="Containers" /><category term="Developer Tools" /><category term="Microservices" /><category term="Modern App Dev" /><category term=".NET" /><category term="containers" /><category term="microservices" /><category term="OpenShift Container Platform" /><category term="Red Hat OpenShift" /><author><name>Bob Davis</name></author><id>https://developers.redhat.com/blog/?p=498747</id><updated>2018-06-14T16:29:50Z</updated><published>2018-06-14T16:29:50Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400"&gt;We are very pleased to announ&lt;/span&gt;&lt;span style="font-weight: 400"&gt;ce the general availability of .NET Core 2.1 for Red Hat Enterprise Linux and OpenShift platforms!&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;.NET Core is the open-source, cross-platform .NET platform for building microservices. .NET Core is designed to provide the best performance at scale for applications that use microservices and containers. Libraries can be shared with other .NET platforms, such as .NET Framework (Windows) and Xamarin (mobile applications). With .NET Core you have the flexibility of building and deploying applications on Red Hat Enterprise Linux or in containers. Your container-based applications and microservices can easily be deployed to your choice of public or private clouds using Red Hat OpenShift. All of the features of OpenShift and Kubernetes for cloud deployments are available to you.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;.NET Core 2.1 continues to broaden its support and tools for microservice development in an open source environment. The latest version of .NET Core includes the following improvements:&lt;/span&gt;&lt;span id="more-498747"&gt;&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Improved build performance&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Improved runtime performance&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Improved networking performance&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;The new &lt;code&gt;Span&amp;#60;T&amp;#62;&lt;/code&gt; based APIs for reducing allocations&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Extended Cryptography APIs&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;API Support for Brotli compression&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;A new way of deploying tools as NuGet Packages&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;This release further reduces platform differences between Windows and Linux.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;As usual, .NET Core 2.1 is available via &lt;/span&gt;&lt;a href="https://developers.redhat.com/products/dotnet/hello-world/"&gt;&lt;span style="font-weight: 400"&gt;traditional “yum” install&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt; (rh-dotnet21) or in containers through our &lt;/span&gt;&lt;a href="https://access.redhat.com/containers/#/search/dotnet"&gt;&lt;span style="font-weight: 400"&gt;container catalog&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;.&lt;/span&gt;&lt;/p&gt; &lt;h3&gt;&lt;span style="font-weight: 400"&gt;Release and support information&lt;/span&gt;&lt;/h3&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Developers may use .NET Core 2.1 to develop and deploy applications on:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Red Hat Enterprise Linux&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Red Hat Enterprise Linux Atomic Host&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Red Hat OpenShift Container Platform  &lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Red Hat OpenShift Online&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Red Hat OpenShift Dedicated&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Red Hat OpenStack Platform&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Following a small number of significant releases in the next few months, .NET Core 2.1 is expected to switch to long-term support (LTS) release as described in the &lt;/span&gt;&lt;a href="https://access.redhat.com/support/policy/updates/net-core"&gt;&lt;span style="font-weight: 400"&gt;Red Hat’s lifecycle documentation&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;. This means that critical updates addressing security and reliability will be offered for 3 years. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;For more information, please visit the following:&lt;/span&gt;&lt;/p&gt; &lt;ol&gt; &lt;li style="font-weight: 400"&gt;&lt;a href="https://access.redhat.com/documentation/en-us/net_core/2.1/html-single/getting_started_guide/index"&gt;&lt;span style="font-weight: 400"&gt;Get Started with .NET Core 2.1!&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Visit &lt;/span&gt;&lt;a href="http://redhatloves.net/"&gt;&lt;span style="font-weight: 400"&gt;RedHatLoves.NET&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;The Red Hat Developer Program &lt;/span&gt;&lt;a href="https://developers.redhat.com/products/dotnet/overview/"&gt;&lt;span style="font-weight: 400"&gt;technology page on .NET Core&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Red Hat Developer &lt;/span&gt;&lt;a href="https://developers.redhat.com/blog/category/programming/dot-net/"&gt;&lt;span style="font-weight: 400"&gt;blogs&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt; on .NET Core&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;a href="https://access.redhat.com/documentation/en-us/net_core/2.1/"&gt;&lt;span style="font-weight: 400"&gt;Product Documentation for .NET Core&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;For complete information on the updates and changes made in this release, &lt;/span&gt;&lt;a href="https://github.com/dotnet/core/blob/master/release-notes/2.1/2.1.0.md"&gt;&lt;span style="font-weight: 400"&gt;please visit the project page on GitHub&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;. Any important differences between Red Hat’s official source build and other builds that are available will be &lt;/span&gt;&lt;a href="https://access.redhat.com/documentation/en-us/net_core/2.1/"&gt;&lt;span style="font-weight: 400"&gt;detailed in our release notes&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;linkname=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;linkname=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;linkname=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;linkname=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;linkname=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;linkname=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;linkname=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;linkname=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fannouncing-net-core-2-1-for-red-hat-platforms%2F&amp;#38;title=Announcing%20.NET%20Core%202.1%20for%20Red%20Hat%20Platforms" data-a2a-url="https://developers.redhat.com/blog/2018/06/14/announcing-net-core-2-1-for-red-hat-platforms/" data-a2a-title="Announcing .NET Core 2.1 for Red Hat Platforms"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/14/announcing-net-core-2-1-for-red-hat-platforms/"&gt;Announcing .NET Core 2.1 for Red Hat Platforms&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/aUpfi5Mos60" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;.NET Core 2.1 is now available for Red Hat Enterprise Linux and OpenShift platforms! .NET Core is the open-source, cross-platform .NET platform for building microservices. .NET Core is designed to provide the best performance at scale.&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/14/announcing-net-core-2-1-for-red-hat-platforms/"&gt;Announcing .NET Core 2.1 for Red Hat Platforms&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/06/14/announcing-net-core-2-1-for-red-hat-platforms/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">498747</post-id><dc:creator>Bob Davis</dc:creator><dc:date>2018-06-14T16:29:50Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/06/14/announcing-net-core-2-1-for-red-hat-platforms/</feedburner:origLink></entry><entry><title>Debugging Memory Issues with Open vSwitch DPDK</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ZoZS5zLebLI/" /><category term="OpenStack" /><category term="Red Hat Enterprise Linux" /><category term="debugging" /><category term="dpdk" /><category term="fast datapath" /><category term="hugepages" /><category term="networking" /><category term="NFV" /><category term="Open vSwitch" /><category term="openvswitch" /><category term="ovs-dpdk" /><category term="Virtualization" /><author><name>Kevin Traynor</name></author><id>https://developers.redhat.com/blog/?p=500667</id><updated>2018-06-14T11:00:48Z</updated><published>2018-06-14T11:00:48Z</published><content type="html">&lt;h2 id="introduction"&gt;Introduction&lt;/h2&gt; &lt;p&gt;This article is about debugging out-of-memory issues with &lt;a href="http://docs.openvswitch.org/en/latest/intro/install/dpdk/"&gt;Open vSwitch with the Data Plane Development Kit&lt;/a&gt; (OvS-DPDK). It explains the situations in which you can run out of memory when using OvS-DPDK and it shows the log entries that are produced in those circumstances. It also shows some other log entries and commands for further debugging.&lt;/p&gt; &lt;p&gt;When you finish reading this article, you will be able to identify that you have an out-of-memory issue and you&amp;#8217;ll know how to fix it. Spoiler: Usually having some more memory on the relevant NUMA node works. It is based on OvS 2.9.&lt;/p&gt; &lt;p&gt;&lt;span id="more-500667"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2 id="background"&gt;Background&lt;/h2&gt; &lt;p&gt;As is normal with DPDK-type applications, it is expected that hugepage memory has been set up and mounted. For further information see &lt;a href="http://docs.openvswitch.org/en/latest/intro/install/dpdk/?highlight=hugepage#setup-hugepages"&gt;set up huge pages&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The next step is to specify the amount of memory pre-allocated for OvS-DPDK. This is done using the Open vSwitch Database (OVSDB). In the case below, 4GB of huge-page memory is pre-allocated on NUMA node 0 and NUMA node 1.&lt;/p&gt; &lt;pre&gt;# ovs-vsctl --no-wait set Open_vSwitch . other_config:dpdk-socket-mem=4096,4096&lt;/pre&gt; &lt;p&gt;The default is 1GB for NUMA 0 if &lt;code&gt;dpdk-socket-mem&lt;/code&gt; is not specified.&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s look at the times when we can run out of memory.&lt;/p&gt; &lt;h2 id="initialization"&gt;Initialization&lt;/h2&gt; &lt;p&gt;You can run out of memory when DPDK is initialized, which happens when &lt;code&gt;ovs-vswitchd&lt;/code&gt; is running and the OVSDB entry &lt;code&gt;dpdk-init&lt;/code&gt; is set to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;A useful log entry to watch for during initialization is this:&lt;/p&gt; &lt;pre&gt;|dpdk|INFO|EAL ARGS: ovs-vswitchd -c 0x1 --socket-mem 4096,4096&lt;/pre&gt; &lt;p&gt;This will confirm that the &lt;code&gt;dpdk-socket-mem&lt;/code&gt; you &lt;em&gt;thought&lt;/em&gt; you were setting was actually set and passed to DPDK (thus avoiding the embarrassment of someone else pointing out that your scripts were wrong).&lt;/p&gt; &lt;p&gt;The most likely way to run out of memory during initialization is that huge page memory was not set up correctly:&lt;/p&gt; &lt;pre&gt;|dpdk|INFO|EAL ARGS: ovs-vswitchd -c 0x1 --socket-mem 4096,4096 |dpdk|INFO|EAL: 32 hugepages of size 1073741824 reserved, but no mounted hugetlbfs found for that size&lt;/pre&gt; &lt;p&gt;Another way is that you are requesting too much memory:&lt;/p&gt; &lt;pre&gt;|dpdk|INFO|EAL ARGS: ovs-vswitchd -c 0x1 --socket-mem 32768,0 |dpdk|ERR|EAL: Not enough memory available on socket 0! Requested: 32768MB, available: 16384MB&lt;/pre&gt; &lt;p&gt;Or you request none at all:&lt;/p&gt; &lt;pre&gt;|dpdk|INFO|EAL ARGS: ovs-vswitchd -c 0x1 --socket-mem 0,0 |dpdk|ERR|EAL: invalid parameters for --socket-mem&lt;/pre&gt; &lt;p&gt;All these issues can be fixed by correctly setting up huge pages and requesting to pre-allocate an appropriate amount.&lt;/p&gt; &lt;h2 id="adding-a-port-changing-mtu"&gt;Adding a Port or Changing the MTU&lt;/h2&gt; &lt;p&gt;These situations are grouped together because they can both result in a new pool of buffers being requested for a port. Where possible, these pools of buffers will be shared and reused, but that is not always possible due to differing port NUMA nodes or MTUs.&lt;/p&gt; &lt;p&gt;For new requests, the size of each buffer is fixed (MTU-based) but the number of buffers can be variable and OvS-DPDK will retry for a lower number of buffers if there is not enough memory for initial requests.&lt;/p&gt; &lt;p&gt;When DPDK cannot provide the requested memory to any one of the requests, it reports the following:&lt;/p&gt; &lt;pre&gt;|dpdk|ERR|RING: Cannot reserve memory&lt;/pre&gt; &lt;p&gt;While that may look serious, it&amp;#8217;s nothing to worry about because OvS handles this and simply retries for a lower amount. If however, the retries do not work then the following will be in the log:&lt;/p&gt; &lt;pre&gt;|netdev_dpdk|ERR|Failed to create memory pool for netdev dpdk0, with MTU 9000 on socket 0: Cannot allocate memory&lt;/pre&gt; &lt;p&gt;This case is an issue for functionality.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;If you were adding a port, it will not be usable.&lt;/li&gt; &lt;li&gt;If you were changing the MTU, the MTU change fails but the port will continue to operate with the previous MTU.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;How can you fix these errors? The general guide would be just to give OvS-DPDK more memory on the relevant NUMA node, or stick with a lower MTU.&lt;/p&gt; &lt;h2 id="starting-a-vm"&gt;Starting a VM&lt;/h2&gt; &lt;p&gt;It doesn&amp;#8217;t seem obvious why you would run out of memory when starting a VM, as opposed to when you are adding a vhost port for it (previous section). The key is vhost NUMA reallocation.&lt;/p&gt; &lt;p&gt;When a VM is started, DPDK checks the NUMA node of the memory shared from the guest. This may result in requesting a new pool of buffers from the same NUMA node. But of course, there might be no memory pre-allocated with &lt;code&gt;dpdk-socket-mem&lt;/code&gt; on that NUMA node, or else there might be insufficient memory left.&lt;/p&gt; &lt;p&gt;The log entry would be similar to the add port/change MTU cases:&lt;/p&gt; &lt;pre&gt;|netdev_dpdk|ERR|Failed to create memory pool for netdev vhost0, with MTU 1500 on socket 1: Cannot allocate memory&lt;/pre&gt; &lt;p&gt;The fix for this is having enough memory on the relevant NUMA node, or changing the libvirt/QEMU settings so VM memory is from a different NUMA node.&lt;/p&gt; &lt;h2 id="runtimeadding-a-portadding-queues"&gt;Runtime, Adding a Port, or Adding Queues&lt;/h2&gt; &lt;p&gt;Didn&amp;#8217;t we already cover &lt;em&gt;adding a port?&lt;/em&gt; Yes, we did; however, this section is for when we get a requested pool of buffers, but some time later that proves to be insufficient.&lt;/p&gt; &lt;p&gt;This might be because there are many ports and queues sharing a pool of buffers and by the time some buffers are reserved for Rx queues, some are in flight processing and some are waiting to be returned from Tx queues, so there just aren&amp;#8217;t enough buffers to go around.&lt;/p&gt; &lt;p&gt;For example, the log entries when this occurs while using a physical NIC could look like this:&lt;/p&gt; &lt;pre&gt;|dpdk|ERR|PMD: ixgbe_alloc_rx_queue_mbufs(): RX mbuf alloc failed queue_id=0 |dpdk|ERR|PMD: ixgbe_dev_rx_queue_start(): Could not alloc mbuf for queue:0 |dpdk|ERR|PMD: ixgbe_dev_start(): Unable to start rxtx queues |dpdk|ERR|PMD: ixgbe_dev_start(): failure in ixgbe_dev_start(): -1 |netdev_dpdk|ERR|Interface dpdk0 start error: Input/output error&lt;/pre&gt; &lt;p&gt;For vhost ports, buffers are not reserved but you could see at runtime that you cannot get a new buffer while polling vhost ports. The log entry could look like this:&lt;/p&gt; &lt;pre&gt;|dpdk(pmd91)|ERR|VHOST_DATA: Failed to allocate memory for mbuf.&lt;/pre&gt; &lt;p&gt;If all the ports are needed, the easiest way to resolve this is to reduce the numbers of Rx queues or reserved buffers for the physical NICs. This can be done with the following command:&lt;/p&gt; &lt;pre&gt;# ovs-vsctl set Interface dpdk0 options:n_rxq=4&lt;/pre&gt; &lt;p&gt;or with this command:&lt;/p&gt; &lt;pre&gt;# ovs-vsctl set Interface dpdk0 options:n_rxq_desc=1024&lt;/pre&gt; &lt;p&gt;Alternatively, memory could be increased to ensure that a large pool of buffers will be available (that is, avoiding retries for lower amounts) but that approach scales only so far.&lt;/p&gt; &lt;h2 id="further-debug"&gt;Further Debugging&lt;/h2&gt; &lt;p&gt;If you run out of memory, there will be an error message in the log. If you want further details about the pools of memory being allocated, reused,  and freed, you can turn on debug mode:&lt;/p&gt; &lt;pre&gt;# ovs-appctl vlog/set netdev_dpdk:console:dbg # ovs-appctl vlog/set netdev_dpdk:syslog:dbg # ovs-appctl vlog/set netdev_dpdk:file:dbg&lt;/pre&gt; &lt;p&gt;Allocated, reused,  and freed messages will look like this:&lt;/p&gt; &lt;pre&gt;|netdev_dpdk|DBG|Allocated "ovs_mp_2030_0_262144" mempool with 262144 mbufs |netdev_dpdk|DBG|Reusing mempool "ovs_mp_2030_0_262144" |netdev_dpdk|DBG|Freeing mempool "ovs_mp_2030_0_262144"&lt;/pre&gt; &lt;p&gt;The name of the pool of buffers (that is, &lt;code&gt;mempool&lt;/code&gt;) gives us some information:&lt;/p&gt; &lt;pre&gt;2030 : Padded size of the buffer (derived from MTU) 0 : NUMA node the memory is allocated from 262144 : Number of buffers in the pool&lt;/pre&gt; &lt;p&gt;There is also a command to show which &lt;code&gt;mempool&lt;/code&gt; a port is using, as well as lots of other details (not shown):&lt;/p&gt; &lt;pre&gt;# ovs-appctl netdev-dpdk/get-mempool-info dpdk0 mempool &amp;#60;ovs_mp_2030_0_262144&amp;#62;@0x7f35ff77ce40 ...&lt;/pre&gt; &lt;h2 id="wrap-up"&gt;Wrap-up&lt;/h2&gt; &lt;p&gt;If you have read to here, it probably means you&amp;#8217;ve hit an issue with OvS-DPDK. Sorry to hear that. Hopefully, after reading the above guide you&amp;#8217;ll be able to identify if the issue was due to running out of memory and you&amp;#8217;ll know how to fix it.&lt;/p&gt; &lt;p&gt;Some guidance on how much memory is required and how to configure OvS-DPDK for multi-NUMA (including &lt;code&gt;dpdk-socket-mem&lt;/code&gt;) can be found in the &lt;a href="https://developers.redhat.com/blog/2018/03/16/ovs-dpdk-hugepage-memory/"&gt;OVS-DPDK: How much memory&lt;/a&gt; and &lt;a href="https://developers.redhat.com/blog/2017/06/28/ovs-dpdk-parameters-dealing-with-multi-numa/"&gt;OVS-DPDK: Multi-NUMA&lt;/a&gt; articles on this blog.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;linkname=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;linkname=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;linkname=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;linkname=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;linkname=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;linkname=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;linkname=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;linkname=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F14%2Fdebugging-ovs-dpdk-memory-issues%2F&amp;#38;title=Debugging%20Memory%20Issues%20with%20Open%20vSwitch%20DPDK" data-a2a-url="https://developers.redhat.com/blog/2018/06/14/debugging-ovs-dpdk-memory-issues/" data-a2a-title="Debugging Memory Issues with Open vSwitch DPDK"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/14/debugging-ovs-dpdk-memory-issues/"&gt;Debugging Memory Issues with Open vSwitch DPDK&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ZoZS5zLebLI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Introduction This article is about debugging out-of-memory issues with Open vSwitch with the Data Plane Development Kit (OvS-DPDK). It explains the situations in which you can run out of memory when using OvS-DPDK and it shows the log entries that are produced in those circumstances. It also shows some other log entries and commands for further [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/14/debugging-ovs-dpdk-memory-issues/"&gt;Debugging Memory Issues with Open vSwitch DPDK&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/06/14/debugging-ovs-dpdk-memory-issues/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">500667</post-id><dc:creator>Kevin Traynor</dc:creator><dc:date>2018-06-14T11:00:48Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/06/14/debugging-ovs-dpdk-memory-issues/</feedburner:origLink></entry></feed>
